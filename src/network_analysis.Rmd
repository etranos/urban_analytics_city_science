---
title: "Network analysis practical: networks of cities"
author: Emmanouil Tranos
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
editor: source
---

## Resources

Some of the materials for this tutorial have been adapted from:

-   the [Origin-destination data with stplanr](https://docs.ropensci.org/stplanr/articles/stplanr-od.html) manual,

-   the [Modelling Population Flows Using Spatial Interaction Models](https://rpubs.com/adam_dennett/376877) tutorial, and

-   [Oshan (2016)](http://openjournals.wu.ac.at/region/paper_175/175.html)

-   [Lovelace, Robin, Jakub Nowosad, and Jannes Muenchow. Geocomputation with R. CRC Press, 2019](https://geocompr.robinlovelace.net/)

## Philosophy of this `RMarkdown` document

As you can see this is a long `.Rmd` document, which has a dual objective. On one hand, it will help you achieve the unit learning outcomes as it provides an implementation of most of the concepts and ideas we discuss for this unit. On the other hand this is almost a representation of a 'real world' workflow. Instead of breaking the code in shorter and maybe more digestible `.Rmd` documents I decided to provide you with a working sequence of all actions I would have taken in order to analyse a network with spatial dimensions such as the network of commuting flows in $2011$. You can use this workflow as the basis for building your own approach and, consequently, code in order to complete this session's project. We will spend at least $2$ sessions to go through this code.

To begin with, create a new `RStudio Project` as a new directory
(File > New Project...) and within it create a 
`source` and `data` directory to store the code and the data accordingly. Instructions 
on how to create such a project, can be found [here](https://bookdown.org/daniel_dauber_io/r4np_book/starting-your-r-projects.html). 
Then, create a new `RMarkdown` document to implement all the below.

## Install and load packages

We will use quite a few packages for this tutorial. Most of the code is based on the `tidyverse` logic -- see [here](https://www.tidyverse.org/) for more info. But the main package we will use for network data wrangling and analysis is `igraph` -- more info [here](https://igraph.org/r/).

**Important**

The below code snippet assumes that all the packages are installed. If you are using
a university PC they are probably not. If they are not installed, you need to do
so by using `install.packages("package.name")`.

```{r setup, include=TRUE, results= 'hide', message=FALSE, warning=FALSE}

library(igraph)
library(knitr)
library(corrplot)
library(tidyverse)
library(geojsonio)
library(stplanr)
library(leaflet)
library(rprojroot)
library(kableExtra)
library(sf)

knitr::opts_chunk$set(echo = TRUE)

# This is the project path
path <- find_rstudio_root_file()
```

## Commuting data and networks

For this tutorial we will use travel to work data from the 2011 UK Census. The data is available [online](http://wicid.ukdataservice.ac.uk/cider/wicid/downloads.php?wicid_Session=742d61be88b0614c3982455e542bc776), but it requires an academic login. After you log in, download the **WU03UK** element, save the .csv on your working directory under a `/data` directory and unzip it. We will use the:

> Location of usual residence and place of work by method of travel to work

for

> Census Merged local authority districts in England and Wales, Council areas in Scotland, Local government districts in Northern Ireland.

The below code loads the data.

```{r data load, include=TRUE, results= 'hide', message=FALSE}

path.data <- paste0(path, "/data/wu03uk_v3/wu03uk_v3.csv")
commuting <- read_csv(path.data)
glimpse(commuting)
```

As you may have noticed, the `commuting` object includes only the codes for the local authorities. Let's try to see these codes.

First for the origins.

```{r unique_la_o, include=TRUE, results= 'markup', message=FALSE}
commuting %>% distinct(`Area of usual residence`)
```

And the same for the destinations (results omitted).

```{r unique_la_d, include=TRUE, results= 'hide', message=FALSE}
commuting %>% distinct(`Area of workplace`)
```

```{block, type='alert alert-warning'}
**Question**: Can you guess the countries these codes refer to?
```

You might have observe some weird codes (OD0000001, OD0000002, OD0000003 and OD0000004). With some simple Google searching we can find the [2011 Census Origin-Destination Data User Guide](https://www.ons.gov.uk/file?uri=/census/2011census/2011censusdata/originanddestinationdata/secureoriginanddestinationtables/2011censusoduserguide_tcm77-383888.pdf), which indicates that these codes do not refer to local authorities:

-   OD0000001 = Mainly work at or from home

-   OD0000002 = Offshore installation

-   OD0000003 = No fixed place

-   OD0000004 = Outside UK

For the sake of simplicity we will remove these non-geographical nodes.

```{r drop non_la, include=TRUE, results= 'asis', message=FALSE}
non.la <- c("OD0000001", "OD0000002", "OD0000003", "OD0000004")
commuting <- commuting %>% 
  filter(!`Area of workplace` %in% non.la)
```

Check the `%in%` [operator](https://stat.ethz.ch/R-manual/R-devel/library/base/html/match.html). Also `!` represents negation.

Now let's do some clean-up of the `commuting` data frame. Let's remind ourselves how the data look like.

```{r la.cleanup, include=TRUE, results= 'markup', message=FALSE}
glimpse(commuting)
```

We are only keeping the English and Wales local authorities by keeping the observations with a local authority code starting from E (for England) and W (for Wales).

```{r la.cleanup2, include=TRUE, results= 'markup', message=FALSE}
commuting <- commuting %>% filter(startsWith(`Area of usual residence`, "E") |
                                  startsWith(`Area of usual residence`, "W")) %>% 
                           filter(startsWith(`Area of workplace`, "E") |
                                  startsWith(`Area of workplace`, "W")) %>% 
  glimpse()
```

We can also see we many rows we dropped with `glimpse()`.

It is very important to distinguish between intra- and inter-local authority flows. In network analysis terms, these are the values we find on the diagonal of an adjacency matrix and refer to the commuting flows within a specific local authority or between different ones. For this exercise we are dropping the intra-local authority flows. Although not used here, we also create a new object with the intra-local authority flows.

```{r la.cleanup3, include=TRUE, results= 'markup', message=FALSE}
commuting.intra <- commuting %>%
  filter(`Area of usual residence` == `Area of workplace`)
commuting <- commuting %>%
  filter(`Area of usual residence` != `Area of workplace`) %>% 
  glimpse()
```

Please note the constant use of `glimpse()` to keep control of how many observations we have and check if we missed anything.

Also, take a note of the `commuting` object, which includes multiple types of commuting flows. Therefore, we will build $3$ different networks:

1.  one for all the commuting flows

2.  one only for train flows

3.  one only for bicycle flows.

```{r seperate commuting objects, include=TRUE, results= 'markup', message=FALSE}

commuting.all <- commuting %>%
  select(`Area of usual residence`,
                `Area of workplace`,
                `All categories: Method of travel to work`) %>%
  rename(o = `Area of usual residence`,     # Area of usual residence is annoyingly
         d = `Area of workplace`,           # long, so I am renaiming theses columns.
         weight = `All categories: Method of travel to work`)

# just FYI this is how you could have achieved the same output using base R
# instead of dplyr of the tidyverse ecosystem
# commuting.all <- commuting[,1:3]
# names(commuting.all)[1] <- "o"
# names(commuting.all)[2] <- "d"
# names(commuting.all)[3] <- "weight"

commuting.train <- commuting %>%
  select(`Area of usual residence`,
         `Area of workplace`,
         `All categories: Method of travel to work`,
         `Train`) %>%
  rename(o = `Area of usual residence`,
         d = `Area of workplace`,
         weight = `All categories: Method of travel to work`) %>%
  # The below code drops all the lines with 0 train flows in order to exclude
  # these edges from the network.
  filter(Train!=0)

commuting.bicycle <- commuting %>%
  select(`Area of usual residence`,
                `Area of workplace`,
                `All categories: Method of travel to work`,
                `Bicycle`) %>%
  rename(o = `Area of usual residence`,
         d = `Area of workplace`,
         weight = `All categories: Method of travel to work`) %>%
  # The below code drops all the lines with 0 bicycle flows in order to exclude
  # these edges from the network.
  filter(Bicycle!=0)
```

Unless you know the local authority codes by hard, it might be useful to also add the corresponding local authority names. These can be easily obtained from the [ONS's Open Geography portal](https://geoportal.statistics.gov.uk/datasets/1b4fb79cc4974048919daf6e1fde5073_0/explore). The below code directly downloads a `GeoJSON` file with the local authorities in England and Wales. If you don't know what a `GeoJSON` file is, have a look [here](https://en.wikipedia.org/wiki/GeoJSON). Boundary data can also be obtained by [UK Data Service](https://borders.ukdataservice.ac.uk/easy_download.html).

For the time being we are only interested in the local authority names and codes. We will use the spatial object later.

**Tip**: the below code downloads the `GeoJSON` file over the web. If you want to run the code multiple times, it might be faster to download the file ones, save it on your hard drive and the point this location to `st_read()`.

```{r la1, include=TRUE, results= 'hide', message=FALSE}
la <-st_read("https://services1.arcgis.com/ESMARspQHYMw9BZ9/arcgis/rest/services/CMLAD_Dec_2011_SGCB_GB_2022/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson")
glimpse(la) 

la.names <- as.data.frame(la) %>% 
  select(cmlad11cd, cmlad11nm)    # all we need is the LA names and codes
```

The next step is to actually create the network objects. The below code creates the `igraph` network objects using the `graph_from_data_frame()` function as we already have all the necessary data in data frames (`commuting.all`, `commuting.train` and `commuting.bicycle`). We then attach the local authority names as an attribute to these networks.

```{r}
net.all <-graph_from_data_frame(commuting.all, directed = TRUE, vertices = la.names)

net.train <-graph_from_data_frame(commuting.train, directed = TRUE, vertices = la.names)

net.bicycle <-graph_from_data_frame(commuting.bicycle, directed = TRUE, vertices = la.names)
```

## Network attributes

The below `igraph` functions illustrate some attributes of the network with all the flows.

```{r attributes, include=TRUE, results= 'markup', message=FALSE}
# It provides information about the type of the net.all object. Not surprisingly,
# it is an igraph network.
class(net.all)

# It displays the network file, the number of nodes and edges (345 and 92,688
# in this case).
net.all

# It displays the vertices (aka nodes)
V(net.all)

# It displays the vertex attributes. In this case the local authority codes.
vertex_attr(net.all) %>% glimpse()
# the output of vertex_attr() is quite long, this is why I chained it with glimpse()

# It displays the edges.
E(net.all) %>% glimpse()
# the output of E() is quite long, this is why I chained it with glimpse()

# It displays the weights for each edge. In our case the weights represent commuters.
edge.attributes(net.all)$weight %>% glimpse()
# as above re: glimpse()

# Asks whether the network is weighted or not
is.weighted(net.all)
```

```{block, type='alert alert-warning'}
**Question**: How many nodes and edges are there for the other types of networks?
What do these differences mean?
```

## Network measures

The below `igraph` functions calculate some simple network measures. Have a look at the lecture slides and the reference list to remind yourselves.

```{r network_measures, include=TRUE, results= 'markup', message=FALSE}

# Network diameter. We do not consider the weights because it affects the measurement.
d.all <- diameter(net.all, directed = TRUE, weights = NA)
d.all

# Average path length
mean_ditst.all <- mean_distance(net.all)
mean_ditst.all

# Network density
dens.all <- edge_density(net.all)
dens.all

# Clustering Coefficient or Transitivity
trans.all <- transitivity(net.all)
trans.all

# Reciprocity
rec.all <- reciprocity(net.all)
rec.all

# Assortativity
ass.all <- assortativity_degree(net.all, directed = T)
ass.all
```

```{block, type='alert alert-warning'}
**Question:** Do the same for the other types of commuting networks and compare the different measures.
Why do we observe these differences?
```

## Centralities

Now we are moving from network-level measures to some node-level ones. Specifically, we will calculate different centrality measures.

```{r centralities, include=TRUE, results= 'markup', message=FALSE}
# Binary in-degree centrality.
in.degree <- degree(net.all, mode = "in")
head(in.degree)

# Binary out-degree centrality.
out.degree <- degree(net.all, mode = "out")
head(out.degree)

# Binary degree centrality.
degree <- degree(net.all, mode = "all")
head(degree)

# The function graph.strength() calculates the weighted degree centrality.

# Weighed in-degree centrality.
w.in.degree <- graph.strength(net.all, mode = "in")
head(w.in.degree)

# Weighed out-degree centrality.
w.out.degree <- graph.strength(net.all, mode = "out")
head(w.out.degree)

# Weighed degree centrality.
w.degree <- graph.strength(net.all, mode = "all")
head(w.degree)

# The function betweenness() calculates betweenness centrality. As before.
btwnss <- betweenness(net.all, weights = NA)
head(btwnss)

# Eigenvector centrality.
eigen <- eigen_centrality(net.all)

# Be careful, eigen has a more complicated structure. Use ?eigen_central to read more. 
# Before goin. forward, let's see the structure of eigen.
str(eigen)

# We are interested in eigen$vector.
head(eigen$vector)

# page rank centrality.
prank <- page_rank(net.all, directed = T)
str(prank) # as before
head(prank$vector)
```

Now that we understood how the above works, let's chain them together to create a `centralities` tibble.

```{r}
centralities <- tibble(
  names = vertex_attr(net.all)[[2]],
  # The above creates a vector with the nodes names (i.e. the local authority names).
  # We are interested in the second elements of the vertex_attr() as the first one 
  # includes the local authority codes. Try str(vertex_attr(net.all)) to see why.
  # the double squared brackets [[]] brings the vertex, while the single one []
  # would have brought a list.
  in.degree = degree(net.all, mode = "in"),
  out.degree = degree(net.all, mode = "out"),
  degree = degree(net.all, mode = "in"),
  w.in.degree = graph.strength(net.all, mode = "in"),
  w.out.degree = graph.strength(net.all, mode = "out"),
  w.degree = graph.strength(net.all, mode = "all"),
  btwnss = betweenness(net.all, weights = NA),
  eigen = eigen_centrality(net.all)$vector,  # note the $vector
  prank = page_rank(net.all, directed = T)$vector) %>% 
  glimpse()
```

Or, if you want a nicer table, you can use `kable()`. **Tip** check out the `kableExtra` package for more options

```{r}
centralities %>% kable(caption = "Centralities") %>% 
  # The following `kableExtra` function introduces a scroll box
  scroll_box(width = "100%", height = "300px")       
```

```{block, type='alert alert-warning'}
**Question**: Can you try to interpret these different centrality measures in the context of our data?
```

This is helpful, but we might also be interested in discussing the rankings: *Which one is the most central local authority in the commuting network?* Instead of reading from the table, we can just calculate the ranks.

To begin with, let's do a test.

```{r centralities_ranks, include=TRUE, results= 'markup', message=FALSE}

test <- centralities %>%
  mutate(rank.test = dense_rank(desc(in.degree))) %>% # We are interested in dense ranking:
                                                      # i.e. two lines with the same value will
                                                      # have the same ranking.
                                                      # desc stands for descending order.
  arrange(rank.test) %>%                              # Arranges the data frame based on rank.test.
  glimpse()
```

```{r centralities_ranks_table, include=TRUE, results= 'markup', message=FALSE}

ranks <- centralities %>%
  mutate_at(vars(in.degree:prank), 
            funs(dense_rank(desc(.)))) # . for all the selected variables

# Adds a prefix r_ before each column name to indicate the ranks
colnames(ranks) <- paste("r", colnames(ranks), sep = "_")


```

```{block, type='alert alert-warning'}
**Question**: Can you quickly compare the `ranks` with the `cetrnalities` object
based on the rankings?
```

```{r centralities_ranks_table2, include=TRUE, results= 'markup', message=FALSE}

head(centralities)
head(ranks)

# So, because both dataframes have the same structure and order we can just use
# cbind().

centralities <- cbind(centralities, ranks) %>% 
  arrange(w.in.degree) %>% 
  select(-r_names) %>% 
  glimpse()

# It combines the centralities (centralities) and ranks (ranks) objects by columns.
# You can imagine it as stacking the columns of ranks after the columns of centralities.
# Since both objects refer to the same observations (i.e. the same rows), we can
# just combine them.


# And this is a nicer table of centralities:
centralities %>% kable(caption = "Centralities") %>% 
  scroll_box(width = "100%", height = "300px")       #Again the `kableExtra` function
```

## Compare centralities

The below code provides a corregram of the different centrality measures.

```{r corrgram, include=TRUE, results= 'markup', message=FALSE}
cor.mat <- cor(centralities[,c(2:10)])
corrplot(cor.mat, type="upper")
```

```{block, type='alert alert-warning'}
**Question:**
Discuss the differences between the different centrality measures in the context
of the commuting network.
```

## Community detection

To begin with, we need to convert our network to an undirected one, as the `fast_greedy` algorithm we are using can only be applied to such networks.

```{r communities, include=TRUE, results= 'markup', message=FALSE}

net.all.und <- as.undirected(net.all,
                             mode=c("mutual"),
                             edge.attr.comb = igraph_opt("edge.attr.comb"))

communities.net.all <- cluster_fast_greedy(net.all.und)

# This provides a summary of the community algorithm:
print(communities.net.all)

# To see how many communities we have, run the below:
length(communities.net.all)

# And these are the community sizes:
sizes(communities.net.all)

# Now, let's create a new object with the community membership
#communities.net.all_membership <- membership(communities.net.all)

# And convert it to a data.frame

communities.net.all_membership <- membership(communities.net.all) %>%
  unclass %>%                          # we first need to unclass the object
  as.data.frame %>%                    # we convert it to a dataframe
  rename(community = ".") %>%          # rename the community column
  rownames_to_column("cmlad11cd") %>%  # we 'move' the rownames to a
                                       # new column in order to do a merge below
  left_join(la.names) %>%              # and now we can merge it with the LA names
  arrange(community) %>%               # arrange based on the community membership
  glimpse()

# this is just a test to see if the `left_join` led to any NAs
sapply(communities.net.all_membership, function(x) sum(is.na(x)))
```

Let's try now to map our output. We need the local authorities shape file we have already loaded.

```{r communities mapping, include=TRUE, results= 'markup', message=FALSE}

# First we merge the `la` object with the community membership
la <- merge(la, communities.net.all_membership, by = "cmlad11cd")
# Please note that I used base R for the above. I could have easily used the dplyr
# equivalent. Which function would this be?

# just a check to see how the merge worked
sapply(la, function(x) sum(is.na(x))) 

# And this is our map
ggplot(la, aes(fill = as.factor(community))) + 
  geom_sf() +
  ggtitle("Communities using the 'fast and greedy' algorithm")
```

```{block, type='alert alert-warning'}
**Question**: What do you think about the output? Can we learn anything? Can you try different community algorithms?
Check [igraph's manual](https://igraph.org/r/doc/)  and [Javed et al (2018)](https://www.sciencedirect.com/science/article/pii/S1084804518300560)
```

## Network Visualisation

The below chunks of code offer some intro to plotting network data. Have a look to see how the code works.

```{r vis, include=TRUE, results= 'markup', message=FALSE}
plot(net.all, # the graph to be plotted
     layout=layout.fruchterman.reingold, # the layout method. see the igraph documentation for details
     main='My first graph in R', # specifies the title
     vertex.label.dist=0.5, # puts the name labels slightly off the dots
     vertex.frame.color='blue', # the colour of the border of the dots
     vertex.label.color='black', # the colour of the name labels
     vertex.label.font=2, # the font of the name labels
     vertex.label=V(net.all)$id, # specifies the labels of the vertices. in this case the 'name' attribute is used
     vertex.label.cex=.5,	# specifies the size of the font of the labels. can also be made to vary
     edge.arrow.size=0.1) # specifies the arrow size
```

Not a very nice outcome :( Let's remove some information

```{r vis2, include=TRUE, results= 'markup', message=FALSE}
plot(net.all, # the graph to be plotted
     layout=layout.fruchterman.reingold, # the layout method. see the igraph documentation for details
     main='My second graph in R',	# specifies the title
     vertex.frame.color='blue', # the colour of the border of the dots
     vertex.label.font=2,	# the font of the name labels
     vertex.label=NA,	# no labels for the vertices
     edge.arrow.size=0, # specifies the arrow size
     vertex.size=5) # vertex size
```

Let's try to only plot nodes with high weighted degree centrality.

```{r vis3, include=TRUE, results= 'markup', message=FALSE}

# The below gives us the 90th percentile:
q <- quantile(strength(net.all), .9)

# Then, we create a network with the nodes we DON'T want to plot. In this case the lowest 90%
low_nodes <- V(net.all)[strength(net.all) < q] # 108659 is the 90% percentile. Feel free to play with different numbers

# And this is the network with the 10% of the most central nodes
net.all.central <- delete.vertices(net.all, low_nodes)

# The below uses the node degree centrality to plot the node size.
# Pay attention to the 0.0001 factor.

plot(net.all.central, # the graph to be plotted
     layout=layout.fruchterman.reingold, # the layout method. see the igraph documentation for details
     main='My third graph in R', # specifies the title
     vertex.frame.color='blue', # the colour of the border of the dots
     vertex.label.font=2,	# the font of the name labels
     vertex.label=V(net.all.central)$id, # no labels for the vertices
     vertex.label.font=1, # the font type of the name labels (1 plain, 2 bold, 3, italic, 4 bold italic, 5 symbol)
     vertex.label.cex=.5,	# specifies the size of the font of the labels. can also be made to vary
     edge.arrow.size=0, # specifies the arrow size
     vertex.size=strength(net.all.central)*0.0001) # defines the node size based on weighted degree centrality
```

Not very nice either...

```{block, type='alert alert-warning'}

For the next time:

1. spend some time browsing the `igraph`'s manual,

2. search for code online to `plot large netwoks in R using igraph`, and

3. use the following tutorials

  - [netVizR](http://mr.schochastics.net/netVizR.html)
(the data can be found [here](http://mr.schochastics.net/#projects) under the
'Network Visualization in R' section

  - [edge-bundling](https://blog.schochastics.net/posts/2021-01-15_non-hierarchical-edge-bundling-in-r/index.html)

in order to produce more meaningful network visualisations of the UK commuting
network.

I am interesting in one or multiple plots with:

- all or a subset of the nodes and edges.
How could you select such a subset?

- the communities you detected.

- varying size of nodes based on a centrality measure. Again, you can
decide to plot a subset of the network based on some network characteristics.

- an *appropriate* to the network layout.
```

## Mapping

Until now we focused mostly on the topology of the network and we ignored its spatial dimension. However, this is an important attribute of the commuting network and we should necessarily consider it and incorporate it in our analysis. To begin with we will map these commuting flows. Bare in mind that this is not a trivial process as, in essence, we need to attach the geographical coordinates to the network nodes and plot the network based on these coordinates. Given the size of our network this might be computationally expensive. It is also challenging to create a meaningful map given the size of the network.

The local authorities spatial object is necessary in order to use the `od2line()` function from the `stplanr` package. This is a very useful function transforms origin to destination (OD) tables to linear spatial objects. In order for this function to work we need the above spatial object with the zones of the origin and destination flows. Importantly it needs to only include the zone codes (i.e. the local authority codes), which should match with the origin and destination codes.This is the `la` spatial object of the local authorities in England and Wales, which has already been loaded in R.

The below code just plots the boundaries of local authorities.

```{r la2, include=TRUE, results= 'markup', message=FALSE}
ggplot(la) + 
  geom_sf() +
  ggtitle("Local authorities")
```

Now let's do some clean-up of the `commuting.all` data frame in order to convert it to a spatial object using the `od2line()` function.

```{r lod2line, include=TRUE, results= 'markup', message=FALSE}
# We start by plotting a histogram of the data. We are using ggplot() as the output
# is nicer, but the simpler hist() could also be used

options(scipen=999) # It prevents R from using scientific notation for numbers
ggplot(commuting.all,
       aes(x=weight)) +
  geom_histogram() +
  geom_vline(aes(xintercept=mean(weight)), # This line of code adds a vertical line to represent the mean
             color="blue", linetype="dashed", size=1)
```

As you can see the flow data is very skewed. So, let's truncate the data and plot a histogram for flows between origin and destinations will less than 1000 people.

```{r lod2line2, include=TRUE, results= 'markup', message=FALSE}
ggplot(commuting.all[commuting.all$weight < 1000,],
       aes(x=weight)) +
  geom_histogram() +
  geom_vline(aes(xintercept=mean(weight)),
             color="blue",
             linetype="dashed",
             size=1)
```

There is a very large number of local authority pairs with very few people commuting between these OD pairs. So, in order to decrease the data and the mapping complexity we will keep only the OD pairs with more than 5 commuters.

```{r truncate, include=TRUE, results= 'markup', message=FALSE}
commuting.all.truncated <- commuting.all %>% 
  filter(weight > 5) %>% 
  glimpse()
```

```{block, type='alert alert-warning'}
**Question:**
How many lines did we filter out?
```

The next chunk of code converts the origin-destination table to a spatial object using the corresponding zones spatial object (la) that we have already loaded.

```{r lod2line3, include=TRUE, results= 'markup', message=FALSE}

# od2line() has some strict requirement regarding data structure. 
# Check ?od2line
# Therefore, we kept only the local authority code and name.
# The actual requirement is to have the the zone code as the 
# first column of the zone object. 
# If you remember, we run the following when we loaded the la object: 
# la.names <- as.data.frame(la) %>% 
#   select(cmlad11cd, cmlad11nm) # all we need is the LA names and codes

travel_network <- od2line(flow = commuting.all.truncated, 
                          zones = la)

# Just to see the class of the new spatial object
class(travel_network)

plot(travel_network)
```

This is a naive plot of the spatial network. We can guess the shape of England and Wales, but this is like a *hairball* network and far from being useful. In order to produce a more useful visualisation we will employ the `leaflet` [package](https://rstudio.github.io/leaflet/), which produces interactive maps using `JaveScript` Libraries.

```{r leaflet, include=TRUE, results= 'markup', message=FALSE}
# this is the colour pallet we are going to use based on 5 quantiles
Flow_pal <- colorQuantile("YlOrBr", domain = travel_network$weight, n=5)

leaflet() %>%
  addTiles() %>%
  addPolylines(
    data = travel_network,
    weight = .1,
    color = ~Flow_pal(weight),
    opacity = .6) %>%
    addLegend("topright",
              pal = Flow_pal,
              values = travel_network$weight,
              title = "Commuting flows in 2011")
```

Let's try now to create an interactive map showing only the flows originating from Bristol and Birmingham.

```{r leaflet2, include=TRUE, results= 'markup', message=FALSE}

# To begin with let's find out the local authority codes for Bristol and Birmingham
# Look up the grep() function. Very useful!
la.names[grep("Bristol", la.names$cmlad11nm),]
la.names[grep("Birmingham", la.names$cmlad11nm),]

# These are E41000023 and E41000281 respectively.

# Next we will create the 'groups' of local authorities
travel_network$la.groups = "Rest"
travel_network$la.groups[travel_network$o == "E41000023"] = "Bristol"
travel_network$la.groups[travel_network$o == "E41000281"] = "Birmingham"

leaflet() %>%
  addTiles() %>%
  addPolylines(
    data = travel_network,
    weight = 1, # Notice the different value for better visual effect when zoom in
    color = ~Flow_pal(weight),
    opacity = .8, # as above
    group = travel_network$la.groups) %>%
  addLayersControl(
    position = "bottomleft",
    overlayGroups = unique(travel_network$la.groups),
    options = layersControlOptions(
      collapsed = FALSE)) %>%
  addLegend("topright",
          pal = Flow_pal,
          values = travel_network$weight,
          title = "Commuting flows in 2011")
```

